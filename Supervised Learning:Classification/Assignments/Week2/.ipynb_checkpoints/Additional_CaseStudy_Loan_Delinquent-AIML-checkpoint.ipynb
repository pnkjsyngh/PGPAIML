{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "DRS bank is facing challenging times. Their NPAs (Non-Performing Assets) has been on a rise recently and a large part of these are due to the loans given to individual customers(borrowers). Chief Risk Officer of the bank decides to put in a scientifically robust framework for approval of loans to individual customers to minimize the risk of loans converting into NPAs and initiates a project for the data science team at the bank. You, as a senior member of the team, are assigned this project.\n",
    "\n",
    "### Objective\n",
    "To identify the criteria to approve loans for an individual customer such that the likelihood of the loan delinquency is minimized\n",
    "\n",
    "### Key questions to be answered\n",
    "What are the factors that drive the behavior of loan delinquency?\n",
    "\n",
    "### Dataset\n",
    "* ID: Customer ID\n",
    "* isDelinquent : indicates whether the customer is delinquent or not (1 => Yes, 0 => No)\n",
    "* term: Loan term in months\n",
    "* gender: Gender of the borrower\n",
    "* age: Age of the borrower\n",
    "* purpose: Purpose of Loan\n",
    "* home_ownership: Status of borrower's home\n",
    "* FICO: FICO (i.e. the bureau score) of the borrower\n",
    "\n",
    "### Domain Information\n",
    "* Transactor – A person who pays his due amount balance full and on time.\n",
    "* Revolver – A person who pays the minimum due amount but keeps revolving his balance and does not pay the full amount.\n",
    "* Delinquent - Delinquency means that you are behind on payments, a person who fails to pay even the minimum due amount.\n",
    "* Defaulter – Once you are delinquent for a certain period your lender will declare you to be in the default stage.\n",
    "* Risk Analytics – A wide domain in the financial and banking industry, basically analyzing the risk of the customer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vL8wmJEThU1y"
   },
   "source": [
    "### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# this will help in making the Python code more structured automatically (good coding practice)\\n%load_ext nb_black\\n\\n# Library to suppress warnings or deprecation notes\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Libraries to help with reading and manipulating data\\n\\nimport pandas as pd\\nimport numpy as np\\n\\n# Library to split data\\nfrom sklearn.model_selection import train_test_split\\n\\n# libaries to help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Removes the limit for the number of displayed columns\\npd.set_option(\\\"display.max_columns\\\", None)\\n# Sets the limit for the number of displayed rows\\npd.set_option(\\\"display.max_rows\\\", 200)\\n\\n# Libraries to build decision tree classifier\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn import tree\\n\\n# To tune different models\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# To get diferent metric scores\\nfrom sklearn.metrics import (\\n    f1_score,\\n    accuracy_score,\\n    recall_score,\\n    precision_score,\\n    confusion_matrix,\\n    plot_confusion_matrix,\\n    make_scorer,\\n)\";\n",
       "                var nbb_formatted_code = \"# this will help in making the Python code more structured automatically (good coding practice)\\n%load_ext nb_black\\n\\n# Library to suppress warnings or deprecation notes\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Libraries to help with reading and manipulating data\\n\\nimport pandas as pd\\nimport numpy as np\\n\\n# Library to split data\\nfrom sklearn.model_selection import train_test_split\\n\\n# libaries to help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Removes the limit for the number of displayed columns\\npd.set_option(\\\"display.max_columns\\\", None)\\n# Sets the limit for the number of displayed rows\\npd.set_option(\\\"display.max_rows\\\", 200)\\n\\n# Libraries to build decision tree classifier\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn import tree\\n\\n# To tune different models\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# To get diferent metric scores\\nfrom sklearn.metrics import (\\n    f1_score,\\n    accuracy_score,\\n    recall_score,\\n    precision_score,\\n    confusion_matrix,\\n    plot_confusion_matrix,\\n    make_scorer,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this will help in making the Python code more structured automatically (good coding practice)\n",
    "%load_ext nb_black\n",
    "\n",
    "# Library to suppress warnings or deprecation notes\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Libraries to help with reading and manipulating data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Library to split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# libaries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Removes the limit for the number of displayed columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# Sets the limit for the number of displayed rows\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "# Libraries to build decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# To tune different models\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# To get diferent metric scores\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    confusion_matrix,\n",
    "    plot_confusion_matrix,\n",
    "    make_scorer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a9ZMNfUNhU14"
   },
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Loan_Delinquent_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying data to another varaible to avoid any changes to original data\n",
    "loan = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the first and last 5 rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dEuSu6e4hU2e"
   },
   "source": [
    "### Understand the shape of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The dataset has 11548 rows and 8 columns of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwAu-vEwhU2m"
   },
   "source": [
    "### Check the data types of the columns for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations -**\n",
    "* isDelinquent is the dependent variable - type integer.\n",
    "* All the dependent variables except for ID are object type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7E1orwlJhU20"
   },
   "source": [
    "### Summary of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations-**   \n",
    "\n",
    "* Most of the loans are for a 36-month term loan.\n",
    "* More males have applied for loans than females.\n",
    "* Most loan applications are for house loans.\n",
    "* Most customers have either mortgaged their houses.\n",
    "* Mostly customers in the age group 20-25 have applied for a loan.\n",
    "* Most customers have a FICO score between 300 and 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for unique values in ID column\n",
    "loan[\"ID\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since all the values in ID column are unique we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan.drop([\"ID\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ie6gSJh8hU28"
   },
   "source": [
    "### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are no missing vaues in out dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Rwx-1ZuhU3D"
   },
   "source": [
    "### Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create labeled barplots\n",
    "\n",
    "\n",
    "def labeled_barplot(data, feature, perc=False, n=None):\n",
    "    \"\"\"\n",
    "    Barplot with percentage at the top\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    perc: whether to display percentages instead of count (default is False)\n",
    "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(data[feature])  # length of the column\n",
    "    count = data[feature].nunique()\n",
    "    if n is None:\n",
    "        plt.figure(figsize=(count + 2, 6))\n",
    "    else:\n",
    "        plt.figure(figsize=(n + 2, 6))\n",
    "\n",
    "    plt.xticks(rotation=90, fontsize=15)\n",
    "    ax = sns.countplot(\n",
    "        data=data,\n",
    "        x=feature,\n",
    "        palette=\"Paired\",\n",
    "        order=data[feature].value_counts().index[:n].sort_values(),\n",
    "    )\n",
    "\n",
    "    for p in ax.patches:\n",
    "        if perc == True:\n",
    "            label = \"{:.1f}%\".format(\n",
    "                100 * p.get_height() / total\n",
    "            )  # percentage of each class of the category\n",
    "        else:\n",
    "            label = p.get_height()  # count of each level of the category\n",
    "\n",
    "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
    "        y = p.get_height()  # height of the plot\n",
    "\n",
    "        ax.annotate(\n",
    "            label,\n",
    "            (x, y),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            size=12,\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )  # annotate the percentage\n",
    "\n",
    "    plt.show()  # show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXoQOPsVhU3h"
   },
   "source": [
    "## Observations on isDelinquent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(loan, \"isDelinquent\", perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 66.9% of the customers are delinquent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXoQOPsVhU3h"
   },
   "source": [
    "## Observations on term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(loan, \"term\", perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 91.7% of the loans are for a 36 month term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXoQOPsVhU3h"
   },
   "source": [
    "## Observations on gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(loan, \"gender\", perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are more male applicants (56.8%) than female applicants (43.2%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXoQOPsVhU3h"
   },
   "source": [
    "## Observations on purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(loan, \"purpose\", perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most loan applications are for house loans (59.7%) followed by car loans (18%)\n",
    "* There are 2 levels named 'other' and 'Other' under the purpose variable. Since we do not have any other information about these, we can merge these levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXoQOPsVhU3h"
   },
   "source": [
    "## Observations on home_ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(loan, \"home_ownership\", perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Very few applicants <10% own their house, Most customers have either mortgaged their houses or live on rent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXoQOPsVhU3h"
   },
   "source": [
    "## Observations on age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(loan, \"age\", perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Almost an equal percentage of people aged 20-25 and >25 have applied for the loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXoQOPsVhU3h"
   },
   "source": [
    "## Observations on FICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(loan, \"FICO\", perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most customers have a FICO score between 300 and 500 (55.2%) followed by a score of greater than 500 (44.8%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan[\"purpose\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can merge the purpose -  'other' and 'Other' together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan[\"purpose\"].replace(\"other\", \"Other\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan[\"purpose\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot stacked bar chart\n",
    "\n",
    "\n",
    "def stacked_barplot(data, predictor, target):\n",
    "    \"\"\"\n",
    "    Print the category counts and plot a stacked bar chart\n",
    "\n",
    "    data: dataframe\n",
    "    predictor: independent variable\n",
    "    target: target variable\n",
    "    \"\"\"\n",
    "    count = data[predictor].nunique()\n",
    "    sorter = data[target].value_counts().index[-1]\n",
    "    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    print(tab1)\n",
    "    print(\"-\" * 120)\n",
    "    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    tab.plot(kind=\"bar\", stacked=True, figsize=(count + 5, 6))\n",
    "    plt.legend(\n",
    "        loc=\"lower left\", frameon=False,\n",
    "    )\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_barplot(loan, \"term\", \"isDelinquent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most loan delinquent customers have taken loan for 36 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_barplot(loan, \"gender\", \"isDelinquent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There's not much difference between male and female customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_barplot(loan, \"purpose\", \"isDelinquent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most loan delinquent customers are those who have applied for house loans followed by car and personal loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_barplot(loan, \"home_ownership\", \"isDelinquent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Those customers who have their own house are less delinquent than the ones who live in a rented place or have mortgaged their home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_barplot(loan, \"age\", \"isDelinquent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Customers between 20-25 years of age are more delinquent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stacked_barplot(loan, \"FICO\", \"isDelinquent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If FICO score is >500 the chances of delinquency decrease quite a lot compared to when FICO score is between 300-500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations - \n",
    "* FICO score and term of loan application appear to be very strong indicators of delinquency.\n",
    "\n",
    "* Other factors appear to be not very good indicators of delinquency. (We can use chi-square tests to determine statistical significance in the association between two categorical variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We observed that a high FICO score means that the chances of delinquency are lower, let us see  if any of the other variables indicate higher a FICO score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_barplot(loan, \"home_ownership\", \"FICO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stacked_barplot(loan, \"age\", \"FICO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stacked_barplot(loan, \"gender\", \"FICO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Observations\n",
    "\n",
    "1. Home ownership and gender seem to have a slight impact on the FICO scores.\n",
    "2. Age seems to have a much bigger impact on FICO scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building - Approach\n",
    "1. Data preparation\n",
    "2. Partition the data into train and test set.\n",
    "3. Built a CART model on the train data.\n",
    "4. Tune the model and prune the tree, if required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loan.drop([\"isDelinquent\"], axis=1)\n",
    "y = loan[\"isDelinquent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the categorical variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows in train data =\", X_train.shape[0])\n",
    "print(\"Number of rows in test data =\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of classes in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"Percentage of classes in test set:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation criterion\n",
    "\n",
    "### Model can make wrong predictions as:\n",
    " \n",
    "1. Predicting a customer will not be behind on payments (Non-Delinquent) but in reality the customer would be behind on payments.\n",
    "\n",
    "2. Predicting a customer will be behind on payments (Delinquent) but in reality the customer would not be behind on payments (Non-Delinquent). \n",
    "\n",
    "\n",
    "### Which case is more important? \n",
    "\n",
    "* If we predict a non-delinquent customer as a delinquent customer bank would lose an opportunity of providing loan to a potential customer.\n",
    "\n",
    "### How to reduce this loss i.e need to reduce False Negatives?\n",
    "*  `recall` should be maximized, the greater the recall higher the chances of minimizing the false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, let's create functions to calculate different metrics and confusion matrix so that we don't have to use the same code repeatedly for each model.\n",
    "* The model_performance_classification_sklearn function will be used to check the model performance of models. \n",
    "* The make_confusion_matrix function will be used to plot confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to compute different metrics to check performance of a classification model built using sklearn\n",
    "def model_performance_classification_sklearn(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check classification model performance\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "\n",
    "    # predicting using the independent variables\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
    "    recall = recall_score(target, pred)  # to compute Recall\n",
    "    precision = precision_score(target, pred)  # to compute Precision\n",
    "    f1 = f1_score(target, pred)  # to compute F1-score\n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\"Accuracy\": acc, \"Recall\": recall, \"Precision\": precision, \"F1\": f1,},\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_sklearn(model, predictors, target):\n",
    "    \"\"\"\n",
    "    To plot the confusion_matrix with percentages\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(predictors)\n",
    "    cm = confusion_matrix(target, y_pred)\n",
    "    labels = np.asarray(\n",
    "        [\n",
    "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
    "            for item in cm.flatten()\n",
    "        ]\n",
    "    ).reshape(2, 2)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=labels, fmt=\"\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_imjVzRxLQC"
   },
   "source": [
    "## Build Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion=\"gini\", random_state=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking model performance on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_perf_train = model_performance_classification_sklearn(\n",
    "    model, X_train, y_train\n",
    ")\n",
    "decision_tree_perf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_sklearn(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking model performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_perf_test = model_performance_classification_sklearn(\n",
    "    model, X_test, y_test\n",
    ")\n",
    "decision_tree_perf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_sklearn(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model is giving good and generalized results on training and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGn7w06uxLQP"
   },
   "source": [
    "## Visualizing the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = list(X.columns)\n",
    "feature_names = column_names\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 30))\n",
    "\n",
    "out = tree.plot_tree(\n",
    "    model,\n",
    "    feature_names=feature_names,\n",
    "    filled=True,\n",
    "    fontsize=9,\n",
    "    node_ids=True,\n",
    "    class_names=True,\n",
    ")\n",
    "for o in out:\n",
    "    arrow = o.arrow_patch\n",
    "    if arrow is not None:\n",
    "        arrow.set_edgecolor(\"black\")\n",
    "        arrow.set_linewidth(1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text report showing the rules of a decision tree -\n",
    "\n",
    "print(tree.export_text(model, feature_names=feature_names, show_weights=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* FICO score, duration of loan and gender are the top 3 important features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearch for Hyperparameter tuning of our tree model \n",
    "* Let's see if we can improve our model performance even more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EGJOqdZUxLQu",
    "outputId": "71d70609-77b9-4ebc-b9a4-01ea37a36275"
   },
   "outputs": [],
   "source": [
    "# Choose the type of classifier.\n",
    "estimator = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "\n",
    "parameters = {\n",
    "    \"max_depth\": [np.arange(2, 50, 5), None],\n",
    "    \"criterion\": [\"entropy\", \"gini\"],\n",
    "    \"splitter\": [\"best\", \"random\"],\n",
    "    \"min_impurity_decrease\": [0.000001, 0.00001, 0.0001],\n",
    "}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = make_scorer(recall_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(estimator, parameters, scoring=acc_scorer, cv=5)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "estimator = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking performance on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_tune_perf_train = model_performance_classification_sklearn(\n",
    "    estimator, X_train, y_train\n",
    ")\n",
    "decision_tree_tune_perf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_sklearn(estimator, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Recall has improved on the training set as compared to the initial model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking model performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_tune_perf_test = model_performance_classification_sklearn(\n",
    "    estimator, X_test, y_test\n",
    ")\n",
    "\n",
    "decision_tree_tune_perf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_sklearn(estimator, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After hyperparameter tuning the model has performance has remained same and the model has become simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "tree.plot_tree(\n",
    "    estimator,\n",
    "    feature_names=feature_names,\n",
    "    filled=True,\n",
    "    fontsize=9,\n",
    "    node_ids=True,\n",
    "    class_names=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We are getting a simplified tree after pre-pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guc7EuIJxLQ-"
   },
   "source": [
    "## Cost Complexity Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "498-a5xCxLQ_"
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4XkCPSWxLRB",
    "outputId": "1283b279-9732-4060-9fbc-251f73ecbae5"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_Wed1SXxLRE",
    "outputId": "21241f0e-0d37-4bc8-f969-0656ee6341d8"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"effective alpha\")\n",
    "ax.set_ylabel(\"total impurity of leaves\")\n",
    "ax.set_title(\"Total Impurity vs effective alpha for training set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsO1CYIxLRG"
   },
   "source": [
    "Next, we train a decision tree using the effective alphas. The last value\n",
    "in ``ccp_alphas`` is the alpha value that prunes the whole tree,\n",
    "leaving the tree, ``clfs[-1]``, with one node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4L-P50vSxLRH",
    "outputId": "5a447f8e-1bef-4792-f718-aba85f4ba341"
   },
   "outputs": [],
   "source": [
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=1, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clfs.append(clf)\n",
    "print(\n",
    "    \"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n",
    "        clfs[-1].tree_.node_count, ccp_alphas[-1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKsOMwt2xLRJ"
   },
   "source": [
    "\n",
    "For the remainder, we remove the last element in\n",
    "``clfs`` and ``ccp_alphas``, because it is the trivial tree with only one\n",
    "node. Here we show that the number of nodes and tree depth decreases as alpha\n",
    "increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QU2un6_sxLRJ",
    "outputId": "88997c0a-1cb8-44fd-9d11-58e08e0fba81"
   },
   "outputs": [],
   "source": [
    "clfs = clfs[:-1]\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "node_counts = [clf.tree_.node_count for clf in clfs]\n",
    "depth = [clf.tree_.max_depth for clf in clfs]\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 7))\n",
    "ax[0].plot(ccp_alphas, node_counts, marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax[0].set_xlabel(\"alpha\")\n",
    "ax[0].set_ylabel(\"number of nodes\")\n",
    "ax[0].set_title(\"Number of nodes vs alpha\")\n",
    "ax[1].plot(ccp_alphas, depth, marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax[1].set_xlabel(\"alpha\")\n",
    "ax[1].set_ylabel(\"depth of tree\")\n",
    "ax[1].set_title(\"Depth vs alpha\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62dQ0wu5xLRL"
   },
   "source": [
    "Recall vs alpha for training and testing sets\n",
    "----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFy56kcixLRS"
   },
   "outputs": [],
   "source": [
    "recall_train = []\n",
    "for clf in clfs:\n",
    "    pred_train = clf.predict(X_train)\n",
    "    values_train = recall_score(y_train, pred_train)\n",
    "    recall_train.append(values_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E5VEnQ8pxLRT"
   },
   "outputs": [],
   "source": [
    "recall_test = []\n",
    "for clf in clfs:\n",
    "    pred_test = clf.predict(X_test)\n",
    "    values_test = recall_score(y_test, pred_test)\n",
    "    recall_test.append(values_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eB0uDF0GxLRW",
    "outputId": "5eab2740-34df-42a8-c07b-6cc64dd72842"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"Recall\")\n",
    "ax.set_title(\"Recall vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, recall_train, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, recall_test, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uIVrmaGxLRZ",
    "outputId": "2665eb21-2f10-4e03-f4b9-7b95dad2dc18",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating the model where we get highest train and test recall\n",
    "index_best_model = np.argmax(recall_test)\n",
    "best_model = clfs[index_best_model]\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking model performance on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_postpruned_perf_train = model_performance_classification_sklearn(\n",
    "    best_model, X_train, y_train\n",
    ")\n",
    "decision_tree_postpruned_perf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_sklearn(best_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking model performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_postpruned_perf_test = model_performance_classification_sklearn(\n",
    "    best_model, X_test, y_test\n",
    ")\n",
    "decision_tree_postpruned_perf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_sklearn(best_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With post-pruning we are getting good and generalized model performance on both training and test set.\n",
    "* The recall has improved further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGn7w06uxLQP"
   },
   "source": [
    "## Visualizing the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRRrogVyxLRg",
    "outputId": "db31ad74-a5dc-4d6c-b070-daa8c97cfc17"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "out = tree.plot_tree(\n",
    "    best_model,\n",
    "    feature_names=feature_names,\n",
    "    filled=True,\n",
    "    fontsize=9,\n",
    "    node_ids=True,\n",
    "    class_names=True,\n",
    ")\n",
    "for o in out:\n",
    "    arrow = o.arrow_patch\n",
    "    if arrow is not None:\n",
    "        arrow.set_edgecolor(\"black\")\n",
    "        arrow.set_linewidth(1)\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDZUOj5BxLRi",
    "outputId": "cc8ab40a-e4fb-45fa-a427-f9d1f7d4abb7"
   },
   "outputs": [],
   "source": [
    "# Text report showing the rules of a decision tree -\n",
    "\n",
    "print(tree.export_text(best_model, feature_names=feature_names, show_weights=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSCypYd3xLRj",
    "outputId": "5a4082d6-1054-4d33-f683-4d15bc1fb410"
   },
   "outputs": [],
   "source": [
    "# importance of features in the tree building ( The importance of a feature is computed as the\n",
    "# (normalized) total reduction of the 'criterion' brought by that feature. It is also known as the Gini importance )\n",
    "\n",
    "print(\n",
    "    pd.DataFrame(\n",
    "        best_model.feature_importances_, columns=[\"Imp\"], index=X_train.columns\n",
    "    ).sort_values(by=\"Imp\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_nDT7r8xLRl",
    "outputId": "61835e49-5425-4e1d-a7c8-037a209d4422"
   },
   "outputs": [],
   "source": [
    "importances = best_model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* FICO score, duration of the loan, and gender remain the most important feature with post-pruning too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing all the decision tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training performance comparison\n",
    "\n",
    "models_train_comp_df = pd.concat(\n",
    "    [\n",
    "        decision_tree_perf_train.T,\n",
    "        decision_tree_tune_perf_train.T,\n",
    "        decision_tree_postpruned_perf_train.T,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "models_train_comp_df.columns = [\n",
    "    \"Decision Tree sklearn\",\n",
    "    \"Decision Tree (Pre-Pruning)\",\n",
    "    \"Decision Tree (Post-Pruning)\",\n",
    "]\n",
    "print(\"Training performance comparison:\")\n",
    "models_train_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test performance comparison\n",
    "\n",
    "models_train_comp_df = pd.concat(\n",
    "    [\n",
    "        decision_tree_perf_test.T,\n",
    "        decision_tree_tune_perf_test.T,\n",
    "        decision_tree_postpruned_perf_test.T,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "models_train_comp_df.columns = [\n",
    "    \"Decision Tree sklearn\",\n",
    "    \"Decision Tree (Pre-Pruning)\",\n",
    "    \"Decision Tree (Post-Pruning)\",\n",
    "]\n",
    "print(\"Test set performance comparison:\")\n",
    "models_train_comp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Decision tree with post-pruning is giving the highest recall on the test set.\n",
    "* The tree with post pruning is not complex and easy to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Insights\n",
    "\n",
    "* FICO, term and gender (in that order) are the most important variables in determining if a borrower will get into a delinquent stage \n",
    "* No borrower shall be given a loan if they are applying for a 36 month term loan and \n",
    "have a FICO score in the range 300-500.\n",
    "* Female borrowers with a FICO score greater than 500 should be our target customers.\n",
    "* Criteria to approve loan according to decision tree model should depend on three main factors - FICO score, duration of loan and gender that is - If the FICO score is less than 500 and the duration of loan is less than 60 months then the customer will not be able to repay the loans. If the customer has greater than 500 FICO score and is a female higher chances that they will repay the loans."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
